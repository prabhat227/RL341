{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cv4te9SDovFo",
    "outputId": "9a0129a9-04c6-4f28-a5f7-572148b4a28d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0:\n",
      "Q-table:\n",
      "[[-0.199 -0.1   -0.1   -0.1   -0.109 -0.109]\n",
      " [10.     0.     0.     0.     0.     0.   ]\n",
      " [ 0.     0.     0.     0.     0.     0.   ]\n",
      " [-0.1   -0.1   -0.109 -0.1    0.     0.   ]\n",
      " [-0.19  -0.19  -0.199 -0.19  -0.1   -0.1  ]\n",
      " [ 0.     0.     0.     0.     0.     0.   ]]\n",
      "---------------------------------\n",
      "Episode 50:\n",
      "Q-table:\n",
      "[[ 1.46788766  2.57237992 30.39771627  7.04467261  5.30626851 10.79372111]\n",
      " [71.63795237 12.98566176  0.          4.35876439 19.         10.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.        ]\n",
      " [ 5.94824958 14.50208866 -0.24267315  4.70358206 50.64801111 16.42302652]\n",
      " [ 7.06258309  6.32361544  2.67490075  7.41230204 34.11541343  4.95111996]\n",
      " [ 0.          0.          0.          0.          0.          0.        ]]\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class QLearning:\n",
    "    def __init__(self, n_states, n_actions, alpha=0.1, gamma=0.9, epsilon=0.1):\n",
    "        self.n_states = n_states\n",
    "        self.n_actions = n_actions\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "        self.Q = np.zeros((n_states, n_actions))\n",
    "\n",
    "    def epsilon_greedy_policy(self, state):\n",
    "        if np.random.rand() < self.epsilon:\n",
    "            return np.random.choice(self.n_actions)\n",
    "        else:\n",
    "            return np.argmax(self.Q[state])\n",
    "\n",
    "    def learn(self, num_episodes, display_interval=50):\n",
    "        for episode in range(num_episodes):\n",
    "            if episode % display_interval == 0:\n",
    "                print(f\"Episode {episode}:\")\n",
    "\n",
    "            state = 0  # Start from the initial state\n",
    "            done = False\n",
    "            total_reward = 0\n",
    "\n",
    "            while not done:\n",
    "                action = self.epsilon_greedy_policy(state)\n",
    "\n",
    "                # Define transitions based on your custom environment\n",
    "                if state == 1:\n",
    "                    next_state = np.random.choice([3, 5])  # Randomly choose between 3 and 5\n",
    "                elif state == 3:\n",
    "                    next_state = np.random.choice([1, 4])  # Randomly choose between 1 and 4\n",
    "                elif state == 5:\n",
    "                    next_state = np.random.choice([1, 4, 5])  # Randomly choose between 1, 4, and 5\n",
    "                elif state == 2:\n",
    "                    next_state = 3\n",
    "                elif state == 4:\n",
    "                    next_state = np.random.choice([0, 3])  # Randomly choose between 0 and 3\n",
    "                elif state == 0:\n",
    "                    next_state = 4\n",
    "                else:\n",
    "                    next_state = state\n",
    "\n",
    "                if next_state == 5:\n",
    "                    reward = 100\n",
    "                else:\n",
    "                    reward = -1\n",
    "\n",
    "                # Update the Q-table\n",
    "                self.Q[state, action] += self.alpha * (reward + self.gamma * np.max(self.Q[next_state]) - self.Q[state, action])\n",
    "\n",
    "                total_reward += reward\n",
    "                state = next_state\n",
    "\n",
    "                if next_state == 5:\n",
    "                    done = True\n",
    "\n",
    "            if episode % display_interval == 0:\n",
    "                print(\"Q-table:\")\n",
    "                print(self.Q)\n",
    "                print(\"---------------------------------\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    n_states = 6  # Number of states (0 to 5)\n",
    "    n_actions = 6  # Number of actions (0 to 5)\n",
    "    agent = QLearning(n_states, n_actions, alpha=0.1, gamma=0.9, epsilon=0.1)\n",
    "    agent.learn(100, display_interval=50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "epOgerU30xIF",
    "outputId": "757c9bfa-6dfb-437f-af72-2ae8b40629e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated π using Monte Carlo: 3.143596\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def monte_carlo_pi(num_samples):\n",
    "    inside_circle = 0\n",
    "\n",
    "    for _ in range(num_samples):\n",
    "        x = random.uniform(0, 1)\n",
    "        y = random.uniform(0, 1)\n",
    "\n",
    "        # Check if the point is inside the unit circle\n",
    "        if x**2 + y**2 <= 1:\n",
    "            inside_circle += 1\n",
    "\n",
    "    # Calculate the estimated value of π\n",
    "    pi_estimate = (inside_circle / num_samples) * 4\n",
    "    return pi_estimate\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    num_samples = 1000000  # Number of random samples\n",
    "    estimated_pi = monte_carlo_pi(num_samples)\n",
    "    print(f\"Estimated π using Monte Carlo: {estimated_pi}\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
